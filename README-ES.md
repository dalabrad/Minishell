# MINI-SHELL PARSER: GU√çA PARA COMPILAR, TESTEAR Y USAR TOKENS

Este documento describe c√≥mo compilar, testear y utilizar el sistema de parsing de comandos de MiniShell. Est√° pensado para que cualquier miembro del equipo pueda probar el parser y utilizar los tokens generados para la fase de ejecuci√≥n.

---

## ESTRUCTURA PRINCIPAL

- `main_test_v.c` ‚Äî Funci√≥n principal de testeo.
- `ft_minisplit.c` ‚Äî Separa el input por pipes.
- `ft_clasifyTokens.c` ‚Äî Clasifica cada palabra/token.
- `utils_parsing.c` ‚Äî Funciones auxiliares (comprobaci√≥n de comillas, espacios, etc).
- `utils_initClean.c` ‚Äî Manejo de memoria.

---

## C√ìMO COMPILAR

```bash
make testv
```

Este comando compilar√° tu Minishell con la funci√≥n `main_test_v.c` para realizar pruebas.

---

## C√ìMO EJECUTAR

```bash
./minishell
```

Y luego puedes introducir comandos como:

```bash
echo "hola mundo" > out.txt | ls -l | wc -l
```

---

## QU√â HACE

1. Separa la entrada por `|`.
2. Tokeniza cada segmento de pipe.
3. Clasifica tokens como `COMMAND`, `ARG`, `RED_OUT`, etc.
4. Muestra informaci√≥n de cada token (incluyendo si estaba entre comillas).
5. Aplica reglas para decidir cu√°l token es el comando en cada pipe.

---

## SALIDA DE EJEMPLO

```bash
=========== PIPE SEGMENTS ===========
-----> Tokenizing: [echo "hola mundo" > out.txt]
‚Üí Token: echo            | Type: COMMAND      | Quoted: no
‚Üí Token: "hola mundo"    | Type: ARG          | Quoted: yes
‚Üí Token: >               | Type: RED_OUT      | Quoted: no
‚Üí Token: out.txt         | Type: ARG          | Quoted: no
Total tokens: 4

-----> Tokenizing: [ ls -l ]
‚Üí Token: ls              | Type: COMMAND      | Quoted: no
‚Üí Token: -l              | Type: OPTION       | Quoted: no
Total tokens: 2

-----> Tokenizing: [ wc -l]
‚Üí Token: wc              | Type: COMMAND      | Quoted: no
‚Üí Token: -l              | Type: OPTION       | Quoted: no
Total tokens: 2
```

---

## ACCESO A TOKENS

En la funci√≥n `main_test_v.c`, cada grupo de tokens est√° guardado as√≠:

```c
t_tokens **tokens_by_segment;
```

Esto es un array de listas enlazadas. Cada posici√≥n representa un pipe:

```c
tokens_by_segment[0] ‚Üí tokens de primer pipe
tokens_by_segment[1] ‚Üí tokens de segundo pipe
...
```

Desde ah√≠ puedes acceder f√°cilmente a los tokens para ejecutar comandos.

---

## LIMPIEZA DE MEMORIA

Al final del ciclo, los tokens y pipe_segments se liberan correctamente:

```c
free_array2(pipe_segments);
for (size_t j = 0; j <= i_pipes; j++)
    free_tokens_list(tokens_by_segment[j]);
free(tokens_by_segment);
```

---

## ERRORES COMUNES

- Aseg√∫rate de que `check_args_fixed()` detecta correctamente las comillas.
- Verifica `pipe_segments[i] != NULL` antes de usarlo.
- Si ves `pipe_segments[n] is NULL`, probablemente `count_splitted()` est√© contando mal.

---

## üß™ RECOMENDACIONES PARA TESTEO

- Probar con `"`, `'`, `>`, `>>`, `<`, `<<`, `|`.
- Validar casos l√≠mite como:
  - Comillas no cerradas
  - Pipes vac√≠os
  - Espacios m√∫ltiples

---

## EXTRA: FUNCIONES √öTILES

- `poly_substr()` ‚Äî Separa palabras manejando comillas.
- `set_command_type()` ‚Äî Decide qu√© token es el comando principal.
- `token_type_str()` ‚Äî Devuelve string representativo del tipo de token.

---

## PARA EL EQUIPO DE EJECUCI√ìN

Usar `tokens_by_segment[i]` como entrada para tu executor. Cada nodo `t_tokens` tiene:

```
char *str          // contenido
t_TokenType type   // tipo de token
int was_quoted     // entrecomillado
```

---